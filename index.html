<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mianzhi Pan | Personal Homepage</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Libre+Baskerville:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css" />
</head>

<body>
  <div class="container">
    <!-- Header Section with Photo on Right -->
    <header class="header">
      <div class="header-content">
        <div class="header-text">
          <h1>Mianzhi Pan</h1>
          <p class="affiliation">School of Artificial Intelligence, Nanjing University</p>
          <p class="bio">
            I am a Ph.D. student at the <a href="http://nlp.nju.edu.cn/homepage/" target="_blank" rel="noopener">NLP Group</a>, Nanjing University, advised by Professor <a href="https://cs.nju.edu.cn/zhangjb/index.htm" target="_blank" rel="noopener">Jianbing Zhang</a>. I received my M.S. from the same group and B.S. from the Kuang Yaming Honors School, Nanjing University. I also worked as a research intern at the Institute for AI Industry Research (AIR), Tsinghua University, under the supervision of Professor <a href="https://zhouh.github.io/" target="_blank" rel="noopener">Hao Zhou</a>.
          </p>
          <p class="bio">
            My research interests lie in <strong>AI for Science</strong>, particularly material representation learning and generative models. Previously, I worked on <strong>Vision–Language Models</strong>, emphasizing fine-grained cross-modal understanding and evaluation.
          </p>
          <div class="contact-links">
            <a href="mailto:panmz@smail.nju.edu.cn">Email</a>
            <span class="separator">/</span>
            <a href="https://github.com/panmianzhi">Github</a>
            <span class="separator">/</span>
            <a href="https://scholar.google.com/citations?user=fcB2s-oAAAAJ&hl=en">Google Scholar</a>
            <span class="separator">/</span>
            <a href="cv.pdf" target="_blank">CV</a>
          </div>
        </div>
        <div class="header-photo">
          <img src="images/IMG_20250627_114613.jpg" alt="Mianzhi Pan" />
        </div>
      </div>
    </header>

    <main class="main-content">

      <section id="experience">
        <h2>Experience</h2>
        <ul>
          <li><strong>2024.9 - present:</strong> Ph.D., <a href="https://ai.nju.edu.cn/main.htm" target="_blank" rel="noopener">School of Artificial Intelligence</a>, Nanjing University</li>
          <li><strong>2024.9 - 2025.10:</strong> Intern, <a href="https://air.tsinghua.edu.cn/" target="_blank" rel="noopener">Institute of AI Industry Research (AIR)</a>, Tsinghua University</li>
          <li><strong>2022.9 - 2024.6:</strong> M.S., <a href="https://ai.nju.edu.cn/main.htm" target="_blank" rel="noopener">School of Artificial Intelligence</a>, Nanjing University</li>
          <li><strong>2018.9 - 2022.6:</strong> B.S., Brain Science and AI, <a href="https://dii.nju.edu.cn/main.htm" target="_blank" rel="noopener">Kuang Yaming Honors School</a>, Nanjing University</li>
        </ul>
      </section>

      <section id="publications">
        <h2>Publications</h2>

        <div class="pub-group" id="vision-language">
          <h3>Vision-Language Learning</h3>
          <div class="pub-item">
            <a href="https://dl.acm.org/doi/abs/10.1145/3581783.3611994" target="_blank" rel="noopener" class="pub-link">
              <img class="pub-thumb" src="images/pubs/acmmm2023_food500.png" alt="Food-500 Caption ACM MM 2023" />
            </a>
            <div class="pub-body">
              <div class="pub-title">Food-500 cap: A fine-grained food caption benchmark for evaluating vision-language models</div>
              <div class="pub-authors">Zheng Ma, <strong>Mianzhi Pan</strong>, Wenhan Wu, et al.</div>
              <div class="pub-venue">ACM Multimedia, 2023</div>
              <p class="pub-brief">A new benchmark to measure fine-grained captioning and cross-modal understanding in food domain, enabling more faithful and diverse VLM generation.</p>
            </div>
          </div>

          <div class="pub-item">
            <a href="https://aclanthology.org/2022.findings-emnlp.421/" target="_blank" rel="noopener" class="pub-link">
              <img class="pub-thumb" src="images/pubs/emnlp2022_alignment.png" alt="EMNLP Findings 2022" />
            </a>
            <div class="pub-body">
              <div class="pub-title">Probing cross-modal semantics alignment capability from the textual perspective</div>
              <div class="pub-authors">Zheng Ma, Shi Zong, <strong>Mianzhi Pan</strong>, et al.</div>
              <div class="pub-venue">Findings of EMNLP, 2022</div>
              <p class="pub-brief">A probing study revealing how well text-only analyses can diagnose cross-modal alignment in large-scale vision-language models.</p>
            </div>
          </div>
        </div>

        <div class="pub-group" id="ai-for-science">
          <h3>AI for Science</h3>
          <div class="pub-item">
            <a href="https://pubs.rsc.org/en/content/articlelanding/2025/dd/d5dd00268k" target="_blank" rel="noopener" class="pub-link">
              <img class="pub-thumb" src="images/pubs/digital_discovery_2025.png" alt="Digital Discovery 2025" />
            </a>
            <div class="pub-body">
              <div class="pub-title">Generative AI-powered inverse design for tailored narrowband molecular emitters</div>
              <div class="pub-authors"><strong>Mianzhi Pan</strong>, Tianhao Tan, Yawen Ouyang, et al.</div>
              <div class="pub-venue">Digital Discovery, 2025</div>
              <p class="pub-brief">A generative pipeline for inverse design of molecular emitters with application-driven spectral properties, enabling rapid discovery cycles.</p>
            </div>
          </div>

          <div class="pub-item">
            <a href="https://openreview.net/forum?id=GL5yVOFPpf" target="_blank" rel="noopener" class="pub-link">
              <img class="pub-thumb" src="images/pubs/iclr2025_extrapolation.png" alt="ICLR Workshop" />
            </a>
            <div class="pub-body">
              <div class="pub-title">Towards Extrapolation in Deep Material Property Regression</div>
              <div class="pub-authors"><strong>Mianzhi Pan</strong>, Jianfei Li, Yawen Ouyang, et al.</div>
              <div class="pub-venue">AI4Mat Workshop @ ICLR 2025</div>
              <p class="pub-brief">Empirical and methodological insights on extrapolation for material property regressors with robust evaluation splits.</p>
            </div>
          </div>
        </div>
      </section>
    </main>

    <footer>
      <p>© 2025 Mianzhi Pan | Hosted on <a href="https://pages.github.com/">GitHub Pages</a></p>
    </footer>
  </div>
</body>
</html>
